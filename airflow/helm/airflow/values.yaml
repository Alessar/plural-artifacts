# Default values for airflow.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

sshConfig:
  id_rsa: dummy
  id_rsa_pub: dummy

secrets:
  redis_password: example

exporter:
  image:
    repository: prom/statsd-exporter
    tag: v0.14.1
    pullPolicy: IfNotPresent
  
  podSecurityContext: {}

  securityContext: {}

  replicas: 1

  service:
    type: ClusterIP
    annotations: {}

  web:
    # The address on which to expose the web interface and generated Prometheus metrics.
    port: 9102

    # Path under which to expose metrics.
    path: /metrics

  serviceMonitor:
    interval: 30s
    scrapeTimeout: 10s
    additionalLabels: {}

  statsd:
    # The UDP port on which to receive statsd metric lines.
    udpPort: 9125

    # The TCP port on which to receive statsd metric lines.
    tcpPort: 9125

    # Maximum size of your metric mapping cache.
    # Relies on least recently used replacement policy if max size is reached.
    cacheSize: 1000

    # Size of internal queue for processing events.
    eventQueueSize: 10000

    # Number of events to hold in queue before flushing.
    eventFlushThreshold: 1000

    # Time interval before flushing events in queue.
    eventFlushInterval: 200ms

    # Metric mapping configuration
    mappingConfig: |-

airflow:
  image:
    repository: dkr.plural.sh/airflow/airflow
    tag: 2.0.1-python3.8
    pullSecret: plural-creds

  postgresql:
    enabled: true
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
    existingSecret: airflow-postgres-password

  prometheusRule:
    enabled: true
  serviceMonitor:
    enabled: true
  
  flower:
    enabled: false
  
  rbac:
    create: true
  
  serviceAccount:
    name: airflow
  
  redis:
    enabled: true
    existingSecret: airflow-redis-password
    existingSecretPasswordKey: redis-password

    cluster:
      enabled: false
      slaveCount: 1

    master:
      resources:
        requests:
          cpu: "10m"
          memory: "32Mi"

      persistence:
        enabled: false

    slave:
      resources:
        requests:
          cpu: "10m"
          memory: "32Mi"

      persistence:
        enabled: false

  airflow:
    executor: CeleryExecutor
    config:
      ## security
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "False"
      AIRFLOW__WEBSERVER__BASE_URL: http://localhost/

      ## dags
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "30"

      ## remote log storage
      AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
      AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "plural"

      AIRFLOW__METRICS__STATSD_ON: "True"
      AIRFLOW__METRICS__STATSD_HOST: "statsd-exporter"
      AIRFLOW__METRICS__STATSD_PORT: "9125"
      AIRFLOW__METRICS__STATSD_PREFIX: "airflow"
    
    usersUpdate: false

    extraPipPackages:
    - airflow-exporter

    variables:
    - key: "environment"
      value: "prod"
    
    pools:
    - name: "pool_1"
      slots: 5
      description: "example pool with 5 slots"
    - name: "pool_2"
      slots: 10
      description: "example pool with 10 slots"

  ingress:
    enabled: true
    web:
      tls:
        enabled: true
        secretName: airflow-tls
      annotations:
        kubernetes.io/tls-acme: "true"
        kubernetes.io/ingress.class: "nginx"
        cert-manager.io/cluster-issuer: letsencrypt-prod
        nginx.ingress.kubernetes.io/force-ssl-redirect: 'true'
        nginx.ingress.kubernetes.io/use-regex: "true"

  web:
    replicas: 1

    webserverConfig:
      ## the full text value to mount as the webserver_config.py file
      ##
      stringOverride: |-
        from flask_appbuilder.security.manager import AUTH_DB
        # use embedded DB for auth
        AUTH_TYPE = AUTH_DB

    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
  
  workers:
    ## if the airflow workers StatefulSet should be deployed
    ##
    enabled: true

    replicas: 2

    ## resource requests/limits for the airflow worker Pods
    ##
    resources:
      requests:
        cpu: "1000m"
        memory: "2Gi"

    podDisruptionBudget:
      enabled: true

      maxUnavailable: "20%"

    autoscaling:
      enabled: true
      maxReplicas: 8
      metrics:
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 80
    celery:
      ## if we should wait for tasks to finish before SIGTERM of the celery worker
      ##
      gracefullTermination: true

      ## how many seconds to wait for tasks to finish before SIGTERM of the celery worker
      ##
      ## WARNING:
      ## - GKE cluster-autoscaler will not respect graceful termination period over 10min
      ## NOTE:
      ## - this gives any running tasks AT MOST 9min to complete
      ##
      gracefullTerminationPeriod: 540

    ## how many seconds to wait after SIGTERM before SIGKILL of the celery worker
    ##
    terminationPeriod: 60
  
  logs:
    ## configs for the logs PVC
    ##
    persistence:
      ## if a persistent volume is mounted at `logs.path`
      ##
      enabled: false
  
  gitSync:
    resources:
      cpu: 50m
      memory: 64Mi

    syncTimeout: 1000